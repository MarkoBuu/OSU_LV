```
#prvi dijagrami i manipuliranje podatcima
#drugi Kmeans
#treci mreza
import pandas as pd
from keras.models import load_model
from sklearn import datasets
from imp import load_module
from matplotlib.colors import ListedColormap
import numpy as np
import matplotlib.pyplot as plt
from sklearn.calibration import LabelEncoder
from sklearn.discriminant_analysis import StandardScaler
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
import keras
from keras import layers
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
#zadtak1
iris = datasets.load_iris()
data = pd.DataFrame(data=iris.data, columns=iris.feature_names)
data['target'] = iris.target
data.to_csv('iris.csv', index=False)
print(data.info)
#a
""" 
data2=data[data['target']==1]
plt.figure()
plt.scatter(data2['sepal length (cm)'],data2['petal length (cm)'],c='r',label='Iris setosa')
data2=data[data['target']==2]
plt.scatter(data2['sepal length (cm)'],data2['petal length (cm)'],c='g',label='Iris virginica')
plt.title("Odnos duljine latice i casice")
plt.xlabel("duljina casice")
plt.ylabel("duljina latica")
plt.legend()
plt.show()
#b
plt.figure()
plt.ylabel("sepal width (cm)")
data3 = data.groupby('target')['sepal width (cm)'].mean()
ax=data3.plot.bar(x='klasa', y='prosjek sirine casice', rot=0).set_title("prosjek sirine casice i klasa")
plt.xlabel("klasa jedinke")
plt.show()
#c
prosjek=data2['sepal width (cm)'].mean()
data5=data2[data2['sepal width (cm)']>prosjek]
print("broj jedinki koji imaju vecu sirinu casice od prosjecne sirine casice te klase:" ,len(data5))
 """
#zadatak2
iris = datasets.load_iris()
print(iris)
target = iris['target']
data = iris['data']
types = iris['target_names']
setosa = data[target==0]
versicolour = data[target==1]
virginica = data[target==2]

plt.scatter(versicolour[:,0], versicolour[:,2], c= "blue")
plt.scatter(virginica[:,0], virginica[:,2], c= "red")
plt.xlabel("Duljina")
plt.ylabel('sirina')
plt.legend(('Versi', 'Virgi'))
plt.show()

setosa_mean = np.mean(setosa[:,3])
versi_mean = np.mean(versicolour[:,3])
virgi_mean = np.mean(virginica[:,3])

plt.bar( types,[setosa_mean, versi_mean, virgi_mean], color = "red")
plt.show()

print(len(virginica[virginica[:,3] > virgi_mean] ))
for i in range(1, 9):
    km = KMeans(n_clusters=i, init="random", n_init=5, random_state=0)
    km.fit(data)
    plt.plot(i, km.inertia_, ".-r", linewidth=2)                                            #J parametar
    plt.xlabel("K")
    plt.ylabel("J")

plt.show()

km = KMeans(n_clusters=3, init="random", n_init=5, random_state=0)
km.fit(data)
labels = km.predict(data)

plt.scatter(data[:,0], data[:,1],c = labels, s=2, label = types)
plt.scatter(km.cluster_centers_[0,0],km.cluster_centers_[0,1], c = "red", label = "Centroid 1")
plt.scatter(km.cluster_centers_[1,0],km.cluster_centers_[1,1], c = "red")
plt.scatter(km.cluster_centers_[2,0],km.cluster_centers_[2,1], c = "red")
plt.legend()
plt.show()

total = len(target)
print(target)
print(labels)

good = np.count_nonzero(np.where(labels == target))

print(f"Total: {total}")
print(f"Good: {good}")
print(f"%: {good/total}")

#zadatak3
X = data[["sepal length (cm)","sepal width (cm)","petal length (cm)","petal width (cm)"]].to_numpy()
y = data["target"].to_numpy().reshape(-1, 1)

encoder = OneHotEncoder()
y = encoder.fit_transform(y).toarray()


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=10)

model = keras.Sequential()
model.add(layers.Dense(10, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(7, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(5, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))


model.compile(optimizer='adam',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

model.fit(X_train,
            y_train,
            epochs = 5,
            batch_size = 7,        
            validation_split = 0.1)
            
model.summary()
model.save("model.keras")

model=load_model("model.keras")
score = model.evaluate(X_test, y_test, verbose=0)
print('Tocnost na testnom skupu podataka:',score[1])

# min - max skaliranje
sc = MinMaxScaler()
Y_train_n = sc.fit_transform(y_train)
Y_test_n = sc.transform(y_test)

predictions=model.predict(X_test)
predictions=np.around(predictions).astype(np.int32)
cm=confusion_matrix(Y_test_n,predictions)
cm_disp=ConfusionMatrixDisplay(cm)
cm_disp.plot()
plt.show()
```